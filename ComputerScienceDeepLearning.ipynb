{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeepeR19/CSCI167_PyTorch_Notebook/blob/main/ComputerScienceDeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlzfpS4Toz-1",
        "outputId": "1d2fe016-8cb6-401d-cb9b-ed65240f28cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kaggle credentials set up.\n"
          ]
        }
      ],
      "source": [
        "#@title 0. Setup: installs and Kaggle credentials\n",
        "!pip install -q kaggle datasets torch torchvision\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Kaggle credentials (one-time per Colab runtime) ---\n",
        "# 1. In Colab go to: Files > Upload, and upload your kaggle.json\n",
        "# 2. Then run this cell.\n",
        "\n",
        "if not Path(\"kaggle.json\").exists():\n",
        "    print(\">>> Upload your kaggle.json in the Files panel or via `files.upload()`.\")\n",
        "else:\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp kaggle.json ~/.kaggle/\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "    print(\"Kaggle credentials set up.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTLphSdJpl3V",
        "outputId": "3583aec4-c956-4ddd-bc3d-785d1bb0259b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/vasukipatel/face-recognition-dataset\n",
            "License(s): CC0-1.0\n",
            "Downloading face-recognition-dataset.zip to data\n",
            " 94% 684M/726M [00:10<00:00, 76.6MB/s]\n",
            "100% 726M/726M [00:10<00:00, 71.0MB/s]\n",
            "Kaggle face dataset downloaded. Inspect directories in the left panel.\n",
            "If needed, adjust FACES_ROOT to point at the folder that contains per-person subfolders.\n"
          ]
        }
      ],
      "source": [
        "  #@title 1. Download Face dataset from Kaggle + set paths\n",
        "\n",
        "DATA_DIR = Path(\"data\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# --- Kaggle face dataset (Vasuki Patel) ---\n",
        "# Dataset description: 2562 images, 31 classes (celebrities). :contentReference[oaicite:3]{index=3}\n",
        "KAGGLE_DATASET = \"vasukipatel/face-recognition-dataset\"\n",
        "KAGGLE_ZIP = DATA_DIR / \"face-recognition-dataset.zip\"\n",
        "FACES_ROOT = DATA_DIR / \"face-recognition-dataset\"  # we will unzip here\n",
        "\n",
        "if not FACES_ROOT.exists():\n",
        "    if not KAGGLE_ZIP.exists():\n",
        "        !kaggle datasets download -d $KAGGLE_DATASET -p $DATA_DIR\n",
        "    !unzip -q $KAGGLE_ZIP -d $FACES_ROOT\n",
        "\n",
        "print(\"Kaggle face dataset downloaded. Inspect directories in the left panel.\")\n",
        "print(\"If needed, adjust FACES_ROOT to point at the folder that contains per-person subfolders.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy2ZABbyq-Rs"
      },
      "outputs": [],
      "source": [
        "#@title 1b. (Alternate) Download Hugging Face face dataset (bigger, 105 classes)\n",
        "\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "USE_HF_FACE_DATASET = False  # <-- set to True if you want HF instead of Kaggle\n",
        "\n",
        "HF_FACE_REPO = \"AI-Solutions-KK/face_recognition_dataset\"\n",
        "HF_FACE_LOCAL = DATA_DIR / \"hf_face_recognition_dataset\"\n",
        "\n",
        "if USE_HF_FACE_DATASET:\n",
        "    snapshot_download(\n",
        "        repo_id=HF_FACE_REPO,\n",
        "        repo_type=\"dataset\",\n",
        "        local_dir=HF_FACE_LOCAL,\n",
        "        local_dir_use_symlinks=False,\n",
        "    )\n",
        "    print(\"Hugging Face face dataset downloaded to:\", HF_FACE_LOCAL)\n",
        "\n",
        "# This dataset has ~18k+ images and 105 identities in a folder-per-person structure. :contentReference[oaicite:5]{index=5}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_InsAiINr8mx",
        "outputId": "bb4cfd83-56c4-4d58-d2e4-3c6a8da4846a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "#@title 2. Imports + device + transforms\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder, MNIST\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# --- Shared transforms for faces (Kaggle or HF) ---\n",
        "IMG_SIZE = 224  # works with ResNet18\n",
        "\n",
        "face_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],   # ImageNet-like normalization\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    ),\n",
        "])\n",
        "\n",
        "# --- Transforms for MNIST (1-channel, 28x28) ---\n",
        "mnist_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # [0,1]\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),  # standard MNIST stats\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdQ9k6dwwXKM"
      },
      "outputs": [],
      "source": [
        "#@title 3.1 HF Face dataset wrapper (used if USE_HF_FACE_DATASET=True)\n",
        "from datasets import load_dataset\n",
        "\n",
        "class HFFaceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Wraps AI-Solutions-KK/face_recognition_dataset as a PyTorch Dataset.\n",
        "    Each example has keys: 'image' (PIL.Image) and 'label' (int in [0, num_classes-1]).\n",
        "    \"\"\"\n",
        "    def __init__(self, split=\"train\", transform=None):\n",
        "        self.ds = load_dataset(HF_FACE_REPO, split=split)\n",
        "        self.transform = transform\n",
        "\n",
        "        # HF already gives 'label' as integer with 105 classes; we keep as-is. :contentReference[oaicite:6]{index=6}\n",
        "        self.num_classes = len(self.ds.features[\"label\"].names)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ex = self.ds[idx]\n",
        "        img = ex[\"image\"]\n",
        "        label = ex[\"label\"]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CloooVLrCoNq"
      },
      "outputs": [],
      "source": [
        "#@title 3.2 Face dataloaders (Kaggle or HF)\n",
        "def get_face_dataloaders(\n",
        "    batch_size=32,\n",
        "    val_split=0.2,\n",
        "    use_hf=USE_HF_FACE_DATASET,\n",
        "):\n",
        "    if use_hf:\n",
        "        full_dataset = HFFaceDataset(split=\"train\", transform=face_transform)\n",
        "        num_classes = full_dataset.num_classes\n",
        "        print(f\"Using Hugging Face face dataset with {num_classes} classes.\")\n",
        "    else:\n",
        "        # Adjust FACES_ROOT if necessary after inspecting directory tree\n",
        "        global FACES_ROOT\n",
        "        if not (FACES_ROOT.exists() and any(FACES_ROOT.iterdir())):\n",
        "            raise RuntimeError(\n",
        "                f\"FACES_ROOT '{FACES_ROOT}' seems empty. \"\n",
        "                \"Open the left file explorer and set FACES_ROOT to the folder with per-person subfolders.\"\n",
        "            )\n",
        "        full_dataset = ImageFolder(root=FACES_ROOT, transform=face_transform)\n",
        "        num_classes = len(full_dataset.classes)\n",
        "        print(f\"Using Kaggle face dataset with {num_classes} classes.\")\n",
        "        print(\"Example classes:\", full_dataset.classes[:5], \"...\")\n",
        "\n",
        "    n_total = len(full_dataset)\n",
        "    n_val = int(val_split * n_total)\n",
        "    n_train = n_total - n_val\n",
        "\n",
        "    train_ds, val_ds = random_split(\n",
        "        full_dataset,\n",
        "        [n_train, n_val],\n",
        "        generator=torch.Generator().manual_seed(42),\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUq1-iSgViWq"
      },
      "outputs": [],
      "source": [
        "#@title 3.3 MNIST dataloaders (for CNN benchmark)\n",
        "\n",
        "def get_mnist_dataloaders(batch_size=64):\n",
        "    \"\"\"\n",
        "    Standard MNIST: 60k train, 10k test, 10 classes. :contentReference[oaicite:7]{index=7}\n",
        "    We'll treat the official test split as our validation set.\n",
        "    \"\"\"\n",
        "    train_ds = MNIST(root=DATA_DIR, train=True, download=True, transform=mnist_transform)\n",
        "    val_ds   = MNIST(root=DATA_DIR, train=False, download=True, transform=mnist_transform)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    num_classes = 10\n",
        "    return train_loader, val_loader, num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVH577dJVl3y"
      },
      "outputs": [],
      "source": [
        "#@title 4.1 Simple CNN (used in multiple experiments)\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, in_channels: int, num_classes: int):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),      # /2\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),      # /4\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),  # global average\n",
        "        )\n",
        "        self.classifier = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPULvFaVYSKv"
      },
      "outputs": [],
      "source": [
        "#@title 4.2 ResNet18 with custom head (for faces only)\n",
        "\n",
        "def make_resnet18_head(num_classes: int, freeze_backbone: bool = False):\n",
        "    weights = ResNet18_Weights.DEFAULT\n",
        "    model = resnet18(weights=weights)\n",
        "    if freeze_backbone:\n",
        "        for p in model.parameters():\n",
        "            p.requires_grad = False\n",
        "    # Replace final FC layer\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(in_features, num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvuL3patYUtv"
      },
      "outputs": [],
      "source": [
        "#@title 5. Training & evaluation utilities\n",
        "\n",
        "def make_optimizer(name: str, model: nn.Module, lr: float):\n",
        "    name = name.lower()\n",
        "    if name == \"sgd\":\n",
        "        return torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-4)\n",
        "    elif name == \"adam\":\n",
        "        return torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    elif name == \"adamw\":\n",
        "        return torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown optimizer {name}\")\n",
        "\n",
        "\n",
        "def accuracy_from_logits(logits, targets):\n",
        "    preds = logits.argmax(dim=1)\n",
        "    correct = (preds == targets).sum().item()\n",
        "    total = targets.size(0)\n",
        "    return correct, total\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        c, t = accuracy_from_logits(outputs, labels)\n",
        "        correct += c\n",
        "        total += t\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            c, t = accuracy_from_logits(outputs, labels)\n",
        "            correct += c\n",
        "            total += t\n",
        "\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "\n",
        "def run_experiment(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer_name=\"sgd\",\n",
        "    lr=1e-3,\n",
        "    epochs=5,\n",
        "    experiment_name=\"exp\",\n",
        "):\n",
        "    model = model.to(device)\n",
        "    optimizer = make_optimizer(optimizer_name, model, lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    history = {\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"val_loss\": [],\n",
        "        \"val_acc\": [],\n",
        "    }\n",
        "\n",
        "    print(f\"\\n=== {experiment_name} ===\")\n",
        "    print(f\"Optimizer: {optimizer_name}, lr={lr}, epochs={epochs}\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        history[\"train_loss\"].append(tr_loss)\n",
        "        history[\"train_acc\"].append(tr_acc)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:02d} | \"\n",
        "            f\"train_loss={tr_loss:.4f}, train_acc={tr_acc*100:.2f}% | \"\n",
        "            f\"val_loss={val_loss:.4f}, val_acc={val_acc*100:.2f}%\"\n",
        "        )\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2hNpUTXYaWl",
        "outputId": "918acbe7-f303-4161-ebb9-75c030b0bd32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using Kaggle face dataset with 2 classes.\n",
            "Example classes: ['Faces', 'Original Images'] ...\n",
            "\n",
            "=== Faces - SimpleCNN + SGD ===\n",
            "Optimizer: sgd, lr=0.01, epochs=5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 01 | train_loss=0.1881, train_acc=93.24% | val_loss=0.1117, val_acc=96.39%\n",
            "Epoch 02 | train_loss=0.1200, train_acc=95.54% | val_loss=0.0880, val_acc=96.68%\n",
            "Epoch 03 | train_loss=0.0938, train_acc=96.66% | val_loss=0.0691, val_acc=97.17%\n",
            "Epoch 04 | train_loss=0.0994, train_acc=96.27% | val_loss=0.1237, val_acc=95.41%\n",
            "Epoch 05 | train_loss=0.1032, train_acc=96.20% | val_loss=0.0505, val_acc=98.34%\n",
            "\n",
            "=== Faces - SimpleCNN + Adam ===\n",
            "Optimizer: adam, lr=0.001, epochs=5\n",
            "Epoch 01 | train_loss=0.1718, train_acc=93.41% | val_loss=0.0859, val_acc=97.56%\n",
            "Epoch 02 | train_loss=0.1046, train_acc=96.49% | val_loss=0.0831, val_acc=97.46%\n",
            "Epoch 03 | train_loss=0.0838, train_acc=96.88% | val_loss=0.0495, val_acc=98.05%\n",
            "Epoch 04 | train_loss=0.0688, train_acc=97.71% | val_loss=0.0570, val_acc=98.14%\n",
            "Epoch 05 | train_loss=0.0689, train_acc=97.80% | val_loss=0.0476, val_acc=98.73%\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 54.9MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Faces - ResNet18 + Adam ===\n",
            "Optimizer: adam, lr=0.0001, epochs=5\n",
            "Epoch 01 | train_loss=0.0182, train_acc=99.20% | val_loss=0.0001, val_acc=100.00%\n",
            "Epoch 02 | train_loss=0.0046, train_acc=99.95% | val_loss=0.0001, val_acc=100.00%\n",
            "Epoch 03 | train_loss=0.0030, train_acc=99.95% | val_loss=0.0005, val_acc=100.00%\n",
            "Epoch 04 | train_loss=0.0003, train_acc=100.00% | val_loss=0.0000, val_acc=100.00%\n",
            "Epoch 05 | train_loss=0.0001, train_acc=100.00% | val_loss=0.0000, val_acc=100.00%\n"
          ]
        }
      ],
      "source": [
        "#@title 6. Run 3 face-recognition experiments\n",
        "\n",
        "# Get face dataloaders\n",
        "face_train_loader, face_val_loader, face_num_classes = get_face_dataloaders(\n",
        "    batch_size=32,\n",
        "    val_split=0.2,\n",
        "    use_hf=USE_HF_FACE_DATASET,\n",
        ")\n",
        "\n",
        "# --- Method 1: Simple CNN + SGD ---\n",
        "face_cnn_sgd = SimpleCNN(in_channels=3, num_classes=face_num_classes)\n",
        "face_cnn_sgd, hist_cnn_sgd = run_experiment(\n",
        "    model=face_cnn_sgd,\n",
        "    train_loader=face_train_loader,\n",
        "    val_loader=face_val_loader,\n",
        "    optimizer_name=\"sgd\",\n",
        "    lr=0.01,\n",
        "    epochs=5,\n",
        "    experiment_name=\"Faces - SimpleCNN + SGD\",\n",
        ")\n",
        "\n",
        "# --- Method 2: Simple CNN + Adam ---\n",
        "face_cnn_adam = SimpleCNN(in_channels=3, num_classes=face_num_classes)\n",
        "face_cnn_adam, hist_cnn_adam = run_experiment(\n",
        "    model=face_cnn_adam,\n",
        "    train_loader=face_train_loader,\n",
        "    val_loader=face_val_loader,\n",
        "    optimizer_name=\"adam\",\n",
        "    lr=1e-3,\n",
        "    epochs=5,\n",
        "    experiment_name=\"Faces - SimpleCNN + Adam\",\n",
        ")\n",
        "\n",
        "# --- Method 3: ResNet18 + Adam (transfer learning) ---\n",
        "face_resnet = make_resnet18_head(num_classes=face_num_classes, freeze_backbone=False)\n",
        "face_resnet, hist_resnet = run_experiment(\n",
        "    model=face_resnet,\n",
        "    train_loader=face_train_loader,\n",
        "    val_loader=face_val_loader,\n",
        "    optimizer_name=\"adam\",\n",
        "    lr=1e-4,  # usually smaller LR for pretrained models\n",
        "    epochs=5,\n",
        "    experiment_name=\"Faces - ResNet18 + Adam\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U1BpNsrviDml",
        "outputId": "99c743a3-b6ec-4001-e6da-f2632c0b7f36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== MNIST - SimpleCNN + Adam ===\n",
            "Optimizer: adam, lr=0.001, epochs=3\n",
            "Epoch 01 | train_loss=0.4293, train_acc=91.17% | val_loss=0.1690, val_acc=95.55%\n",
            "Epoch 02 | train_loss=0.0921, train_acc=97.69% | val_loss=0.1850, val_acc=94.26%\n",
            "Epoch 03 | train_loss=0.0628, train_acc=98.32% | val_loss=0.1554, val_acc=94.90%\n"
          ]
        }
      ],
      "source": [
        "#@title 7. MNIST benchmark with SimpleCNN + Adam\n",
        "\n",
        "mnist_train_loader, mnist_val_loader, mnist_num_classes = get_mnist_dataloaders(batch_size=128)\n",
        "\n",
        "# Note: MNIST is 1-channel (grayscale), 28x28.\n",
        "mnist_cnn = SimpleCNN(in_channels=1, num_classes=mnist_num_classes)\n",
        "\n",
        "mnist_cnn, hist_mnist = run_experiment(\n",
        "    model=mnist_cnn,\n",
        "    train_loader=mnist_train_loader,\n",
        "    val_loader=mnist_val_loader,\n",
        "    optimizer_name=\"adam\",\n",
        "    lr=1e-3,\n",
        "    epochs=3,\n",
        "    experiment_name=\"MNIST - SimpleCNN + Adam\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRjMOce6iQfR",
        "outputId": "5805c2c1-98a1-44c6-96d0-c566c403b793",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Faces - SimpleCNN + SGD  : 98.33984375 %\n",
            "Faces - SimpleCNN + Adam : 98.73046875 %\n",
            "Faces - ResNet18 + Adam  : 100.0 %\n",
            "MNIST - SimpleCNN + Adam : 94.89999999999999 %\n"
          ]
        }
      ],
      "source": [
        "#@title 8. Quick comparison of final validation accuracies\n",
        "\n",
        "def final_val_acc(history):\n",
        "    return history[\"val_acc\"][-1] * 100\n",
        "\n",
        "print(\"Faces - SimpleCNN + SGD  :\", final_val_acc(hist_cnn_sgd),  \"%\")\n",
        "print(\"Faces - SimpleCNN + Adam :\", final_val_acc(hist_cnn_adam), \"%\")\n",
        "print(\"Faces - ResNet18 + Adam  :\", final_val_acc(hist_resnet),   \"%\")\n",
        "print(\"MNIST - SimpleCNN + Adam :\", final_val_acc(hist_mnist),    \"%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMg0ONwjKaYWn/UmOMz84nO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}